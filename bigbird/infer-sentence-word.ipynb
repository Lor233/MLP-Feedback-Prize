{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8523a158",
   "metadata": {
    "papermill": {
     "duration": 0.021776,
     "end_time": "2021-12-24T18:56:32.200543",
     "exception": false,
     "start_time": "2021-12-24T18:56:32.178767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch BigBird NER Baseline - CV 0.615\n",
    "This notebook is a PyTorch starter notebook for Kaggle's \"Feedback Prize - Evaluating Student Writing\" Competition. It demonstrates how to train, infer, and submit a model to Kaggle without internet. Currently this notebook uses\n",
    "\n",
    "* backbone BigBird  (with HuggingFace's head for TokenClassification)\n",
    "* NER formulation (with `is_split_into_words=True` tokenization)\n",
    "* one fold\n",
    "\n",
    "By changing a few lines of code, we can use this notebook to evaluate different PyTorch backbones! And we can run all sorts of other experiments. If we try a backbone that doesn't accept 1024 wide tokens (like BigBird or LongFormer), then we can add a sliding window to train and inference. BigBird is a new SOTA transformer with arXiv paper [here][3] which can accept large token inputs as wide as 4096!\n",
    "\n",
    "The model in this notebook uses HuggingFace's `AutoModelForTokenClassification`. If we want a custom head, we could use `AutoModel` and then build our own head. See my TensorFlow notebook [here][2] for an example.\n",
    "\n",
    "The tokenization process uses `tokenizer(txt.split(), is_split_into_words=True)`, note that this ignores characters like `\\n`. If we want our model to see new paragraphs, we need to rewrite this code and avoid `is_split_into_words=True`. See my TensorFlow notebook [here][2] for an example.\n",
    "\n",
    "This notebook uses many code cells from Raghavendrakotala's great notebook [here][1]. Don't forget to upvote Raghavendrakotala's notebook :-)\n",
    "\n",
    "[1]: https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "[2]: https://www.kaggle.com/cdeotte/tensorflow-longformer-ner-cv-0-617\n",
    "[3]: https://arxiv.org/abs/2007.14062"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f697b1",
   "metadata": {
    "papermill": {
     "duration": 0.020383,
     "end_time": "2021-12-24T18:56:32.243330",
     "exception": false,
     "start_time": "2021-12-24T18:56:32.222947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration\n",
    "This notebook can either train a new model or load a previously trained model (made from previous notebook version). Furthermore, this notebook can either create new NER labels or load existing NER labels (made from previous notebook version). In this notebook version, we will load model and load NER labels.\n",
    "\n",
    "Also this notebook can load huggingface stuff (like tokenizers) from a Kaggle dataset, or download it from internet. (If it downloads from internet, you can then put it in a Kaggle dataset, so next time you can turn internet off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67498c5a-c986-4c6c-8ed2-054a2ad8049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a146dd",
   "metadata": {
    "papermill": {
     "duration": 0.039536,
     "end_time": "2021-12-24T18:56:32.303289",
     "exception": false,
     "start_time": "2021-12-24T18:56:32.263753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# DECLARE HOW MANY GPUS YOU WISH TO USE. \n",
    "# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n",
    "\n",
    "# VERSION FOR SAVING MODEL WEIGHTS\n",
    "TRAIN_VER = 3\n",
    "LOAD_VER = 3\n",
    "\n",
    "# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n",
    "# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\n",
    "LOAD_TOKENS_FROM = 'NER_token'\n",
    "\n",
    "# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n",
    "# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\n",
    "LOAD_MODEL_FROM = 'trained_model'\n",
    "# LOAD_MODEL_FROM = None\n",
    "\n",
    "# IF FOLLOWING IS NONE, THEN NOTEBOOK \n",
    "# USES INTERNET AND DOWNLOADS HUGGINGFACE \n",
    "# CONFIG, TOKENIZER, AND MODEL\n",
    "# DOWNLOADED_MODEL_PATH = '../input/py-bigbird-v26' \n",
    "DOWNLOADED_MODEL_PATH = None\n",
    "\n",
    "if DOWNLOADED_MODEL_PATH is None:\n",
    "    DOWNLOADED_MODEL_PATH = 'model'    \n",
    "MODEL_NAME = 'google/bigbird-roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844706b2",
   "metadata": {
    "papermill": {
     "duration": 1.773177,
     "end_time": "2021-12-24T18:56:34.097096",
     "exception": false,
     "start_time": "2021-12-24T18:56:32.323919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "config = {'model_name': MODEL_NAME,\n",
    "         'max_length': 1024,\n",
    "         # 'train_batch_size':4,\n",
    "         # 'valid_batch_size':4,\n",
    "         'train_batch_size':3,\n",
    "         'valid_batch_size':3,\n",
    "         'epochs':5,\n",
    "         'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n",
    "         'max_grad_norm':10,\n",
    "         'device': 'cuda' if cuda.is_available() else 'cpu'}\n",
    "\n",
    "# THIS WILL COMPUTE VAL SCORE DURING COMMIT BUT NOT DURING SUBMIT\n",
    "COMPUTE_VAL_SCORE = True\n",
    "if len( os.listdir('../data/test') ) > 5:\n",
    "      COMPUTE_VAL_SCORE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636dadb",
   "metadata": {
    "papermill": {
     "duration": 0.040966,
     "end_time": "2021-12-24T18:56:34.171732",
     "exception": false,
     "start_time": "2021-12-24T18:56:34.130766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How To Submit PyTorch Without Internet\n",
    "Many people ask me, how do I submit PyTorch models without internet? With HuggingFace Transformer, it's easy. Just download the following 3 things (1) model weights, (2) tokenizer files, (3) config file, and upload them to a Kaggle dataset. Below shows code how to get the files from HuggingFace for Google's BigBird-base. But this same code can download any transformer, like for example roberta-base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55dc175",
   "metadata": {
    "papermill": {
     "duration": 8.963092,
     "end_time": "2021-12-24T18:56:43.170108",
     "exception": false,
     "start_time": "2021-12-24T18:56:34.207016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:\\Anaconda3\\lib\\site-packages\\torchaudio\\backend\\utils.py:67: UserWarning: No audio backend is available.\n",
      "  warnings.warn('No audio backend is available.')\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "if DOWNLOADED_MODEL_PATH == 'model' and not os.path.exists('model'):\n",
    "    os.mkdir('model')\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
    "    tokenizer.save_pretrained('model')\n",
    "\n",
    "    config_model = AutoConfig.from_pretrained(MODEL_NAME) \n",
    "    config_model.num_labels = 15\n",
    "    config_model.save_pretrained('model')\n",
    "\n",
    "    backbone = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, \n",
    "                                                               config=config_model)\n",
    "    backbone.save_pretrained('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ae13a",
   "metadata": {
    "papermill": {
     "duration": 0.020416,
     "end_time": "2021-12-24T18:56:43.211378",
     "exception": false,
     "start_time": "2021-12-24T18:56:43.190962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data and Libraries\n",
    "In addition to loading the train dataframe, we will load all the train and text files and save them in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645e0f5e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.027699,
     "end_time": "2021-12-24T18:56:43.259877",
     "exception": false,
     "start_time": "2021-12-24T18:56:43.232178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np, os \n",
    "import pandas as pd, gc \n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8bd1d5",
   "metadata": {
    "papermill": {
     "duration": 1.863642,
     "end_time": "2021-12-24T18:56:45.144220",
     "exception": false,
     "start_time": "2021-12-24T18:56:43.280578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144293, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "print( train_df.shape )\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c30751f",
   "metadata": {
    "papermill": {
     "duration": 0.063091,
     "end_time": "2021-12-24T18:56:45.230167",
     "exception": false,
     "start_time": "2021-12-24T18:56:45.167076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>During a group project, have you ever asked a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>80% of Americans believe seeking multiple opin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>When people ask for advice,they sometimes talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  0FB0700DAF44  During a group project, have you ever asked a ...\n",
       "1  18409261F5C2  80% of Americans believe seeking multiple opin...\n",
       "2  D46BCB48440A  When people ask for advice,they sometimes talk...\n",
       "3  D72CB1C11673  Making choices in life can be very difficult. ...\n",
       "4  DF920E0A7337  Have you ever asked more than one person for h..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "test_names, test_texts = [], []\n",
    "for f in list(os.listdir('../data/test')):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    test_texts.append(open('../data/test/' + f, 'r').read())\n",
    "test_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\n",
    "test_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3067e7e2",
   "metadata": {
    "papermill": {
     "duration": 58.996899,
     "end_time": "2021-12-24T18:57:44.249132",
     "exception": false,
     "start_time": "2021-12-24T18:56:45.252233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15594/15594 [00:03<00:00, 4365.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>Driverless cars are exaclty what you would exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>Dear: Principal\\n\\nI am arguing against the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001552828BD0</td>\n",
       "      <td>Would you be able to give your car up? Having ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  0000D23A521A  Some people belive that the so called \"face\" o...\n",
       "1  00066EA9880D  Driverless cars are exaclty what you would exp...\n",
       "2  000E6DE9E817  Dear: Principal\\n\\nI am arguing against the po...\n",
       "3  001552828BD0  Would you be able to give your car up? Having ...\n",
       "4  0016926B079C  I think that students would benefit from learn..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "test_names, train_texts = [], []\n",
    "for f in tqdm(list(os.listdir('../data/train'))):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    train_texts.append(open('../data/train/' + f, 'r').read())\n",
    "train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfcef8",
   "metadata": {
    "papermill": {
     "duration": 0.168711,
     "end_time": "2021-12-24T18:57:44.586488",
     "exception": false,
     "start_time": "2021-12-24T18:57:44.417777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert Train Text to NER Labels\n",
    "We will now convert all text words into NER labels and save in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c207d26e",
   "metadata": {
    "papermill": {
     "duration": 14.170019,
     "end_time": "2021-12-24T18:57:58.923453",
     "exception": false,
     "start_time": "2021-12-24T18:57:44.753434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15594, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E112CE5938F4</td>\n",
       "      <td>Segoing Cowboys is a good program that I think...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13326EED1708</td>\n",
       "      <td>Yes I agree that Venus is dangerous place, but...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>Facial action coding sytsem should be used bec...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E676D0FB128A</td>\n",
       "      <td>My fellow citizens, there are many reasons why...</td>\n",
       "      <td>[O, O, O, B-Position, I-Position, I-Position, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9A03E46C0A51</td>\n",
       "      <td>Dear Principal,\\n\\nI believe that changing the...</td>\n",
       "      <td>[O, O, B-Position, I-Position, I-Position, I-P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  E112CE5938F4  Segoing Cowboys is a good program that I think...   \n",
       "1  13326EED1708  Yes I agree that Venus is dangerous place, but...   \n",
       "2  DD3F7252F887  Facial action coding sytsem should be used bec...   \n",
       "3  E676D0FB128A  My fellow citizens, there are many reasons why...   \n",
       "4  9A03E46C0A51  Dear Principal,\\n\\nI believe that changing the...   \n",
       "\n",
       "                                            entities  \n",
       "0  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "1  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "2  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "3  [O, O, O, B-Position, I-Position, I-Position, ...  \n",
       "4  [O, O, B-Position, I-Position, I-Position, I-P...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f'{LOAD_TOKENS_FROM}/train_NER.csv'):\n",
    "    all_entities = []\n",
    "    for ii, i in enumerate(train_text_df.iterrows()):\n",
    "        if ii%100==0: print(ii, ', ' ,end='')\n",
    "        total = i[1]['text'].split().__len__()\n",
    "        entities = [\"O\"] * total\n",
    "        # print(total)\n",
    "        for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n",
    "            discourse = j[1]['discourse_type']\n",
    "            list_ix = [int(x) for x in j[1]['predictionstring'].split(' ')]\n",
    "            entities[list_ix[0]] = f\"B-{discourse}\"\n",
    "            for k in list_ix[1:]: \n",
    "                # entities[k] = f\"I-{discourse}\"\n",
    "                try:\n",
    "                    entities[k] = f\"I-{discourse}\"\n",
    "                except:\n",
    "                    print(len(entities))\n",
    "                    print(k)\n",
    "        all_entities.append(entities)\n",
    "    train_text_df['entities'] = all_entities\n",
    "    train_text_df.to_csv('train_NER.csv',index=False)\n",
    "    \n",
    "else:\n",
    "    from ast import literal_eval\n",
    "    train_text_df = pd.read_csv(f'{LOAD_TOKENS_FROM}/train_NER.csv')\n",
    "    # pandas saves lists as string, we must convert back\n",
    "    train_text_df.entities = train_text_df.entities.apply(lambda x: literal_eval(x) )\n",
    "    \n",
    "print( train_text_df.shape )\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27e0b80",
   "metadata": {
    "papermill": {
     "duration": 0.176747,
     "end_time": "2021-12-24T18:57:59.269256",
     "exception": false,
     "start_time": "2021-12-24T18:57:59.092509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATE DICTIONARIES THAT WE CAN USE DURING TRAIN AND INFER\n",
    "output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n",
    "          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n",
    "\n",
    "labels_to_ids = {v:k for k,v in enumerate(output_labels)}\n",
    "ids_to_labels = {k:v for k,v in enumerate(output_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd2d164",
   "metadata": {
    "papermill": {
     "duration": 0.176108,
     "end_time": "2021-12-24T18:57:59.613066",
     "exception": false,
     "start_time": "2021-12-24T18:57:59.436958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-Lead': 1,\n",
       " 'I-Lead': 2,\n",
       " 'B-Position': 3,\n",
       " 'I-Position': 4,\n",
       " 'B-Claim': 5,\n",
       " 'I-Claim': 6,\n",
       " 'B-Counterclaim': 7,\n",
       " 'I-Counterclaim': 8,\n",
       " 'B-Rebuttal': 9,\n",
       " 'I-Rebuttal': 10,\n",
       " 'B-Evidence': 11,\n",
       " 'I-Evidence': 12,\n",
       " 'B-Concluding Statement': 13,\n",
       " 'I-Concluding Statement': 14}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66a066ef-33be-4bc7-9cf5-da42db7611e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = train_dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ea021a-c784-43ec-b7d2-b2d18500bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_text = '[CLS] ' + text.replace('.', '. [SEP]')\n",
    "# encoding = tokenizer(pre_text.split(),\n",
    "#                     is_split_into_words=True,\n",
    "#                     add_special_tokens=False,\n",
    "#                     return_offsets_mapping=True, \n",
    "#                     padding='max_length', \n",
    "#                     truncation=True, \n",
    "#                     max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b2eb6b-da26-48a1-907c-11b347341b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f416c69-9dc2-4722-b469-8addd0b95aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoding['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f38ce",
   "metadata": {
    "papermill": {
     "duration": 0.166097,
     "end_time": "2021-12-24T18:57:59.945482",
     "exception": false,
     "start_time": "2021-12-24T18:57:59.779385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the dataset function\n",
    "Below is our PyTorch dataset function. It always outputs tokens and attention. During training it also provides labels. And during inference it also provides word ids to help convert token predictions into word predictions.\n",
    "\n",
    "Note that we use `text.split()` and `is_split_into_words=True` when we convert train text to labeled train tokens. This is how the HugglingFace tutorial does it. However, this removes characters like `\\n` new paragraph. If you want your model to see new paragraphs, then we need to map words to tokens ourselves using `return_offsets_mapping=True`. See my TensorFlow notebook [here][1] for an example.\n",
    "\n",
    "Some of the following code comes from the example at HuggingFace [here][2]. However I think the code at that link is wrong. The HuggingFace original code is [here][3]. With the flag `LABEL_ALL` we can either label just the first subword token (when one word has more than one subword token). Or we can label all the subword tokens (with the word's label). In this notebook version, we label all the tokens. There is a Kaggle discussion [here][4]\n",
    "\n",
    "[1]: https://www.kaggle.com/cdeotte/tensorflow-longformer-ner-cv-0-617\n",
    "[2]: https://huggingface.co/docs/transformers/custom_datasets#tok_ner\n",
    "[3]: https://github.com/huggingface/transformers/blob/86b40073e9aee6959c8c85fcba89e47b432c4f4d/examples/pytorch/token-classification/run_ner.py#L371\n",
    "[4]: https://www.kaggle.com/c/feedback-prize-2021/discussion/296713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ec4e93-6f56-4146-95e9-46b9903a2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_ALL_SUBTOKENS = True\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, get_wids):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.get_wids = get_wids # for validation\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        text = self.data.text[index]        \n",
    "        word_labels = self.data.entities[index] if not self.get_wids else None\n",
    "\n",
    "        # TOKENIZE TEXT\n",
    "        text = '[CLS] ' + text.replace('. ', '. [SEP] ')\n",
    "        encoding = self.tokenizer(text.split(),\n",
    "                             is_split_into_words=True,\n",
    "                             add_special_tokens=False,\n",
    "                             #return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        word_ids = encoding.word_ids()  \n",
    "        input_ids = encoding['input_ids']\n",
    "        \n",
    "        # CREATE TARGETS\n",
    "        if not self.get_wids:\n",
    "            previous_word_idx = None\n",
    "            sen_count = 1\n",
    "            label_ids = []\n",
    "            sen_label_ids = []\n",
    "            \n",
    "            for i, word_idx in enumerate(word_ids):                            \n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif input_ids[i] == 65:\n",
    "                    label_ids.append(-100)\n",
    "                elif input_ids[i] == 66:\n",
    "                    label_ids.append( max(sen_label_ids, key=sen_label_ids.count) )\n",
    "                    sen_label_ids = []\n",
    "                    sen_count += 1\n",
    "                elif word_idx != previous_word_idx:              \n",
    "                    label_ids.append( labels_to_ids[word_labels[word_idx-sen_count]] )\n",
    "                    sen_label_ids.append(label_ids[-1])\n",
    "                else:\n",
    "                    if LABEL_ALL_SUBTOKENS:\n",
    "                        label_ids.append( labels_to_ids[word_labels[word_idx-sen_count]] )\n",
    "                        sen_label_ids.append(label_ids[-1])\n",
    "                    else:\n",
    "                        label_ids.append(-100)\n",
    "                previous_word_idx = word_idx\n",
    "            encoding['labels'] = label_ids\n",
    "\n",
    "        # CONVERT TO TORCH TENSORS\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        if self.get_wids: \n",
    "            word_ids2 = []\n",
    "            for i, w in enumerate(word_ids):\n",
    "                if w is None:\n",
    "                    word_ids2.append(-1)\n",
    "                elif input_ids[i] == 65 or input_ids[i] == 66:\n",
    "                    word_ids2.append(-1)\n",
    "                else:\n",
    "                    word_ids2.append(w)\n",
    "            # word_ids2 = [w if w is not None else -1 for w in word_ids]\n",
    "            item['wids'] = torch.as_tensor(word_ids2)\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b6eaea0-3e88-4ecb-8f76-79fe7543cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Return an array that maps character index to index of word in list of split() words\n",
    "def split_mapping(unsplit):\n",
    "    splt = unsplit.split()\n",
    "    offset_to_wordidx = np.full(len(unsplit),-1)\n",
    "    txt_ptr = 0\n",
    "    for split_index, full_word in enumerate(splt):\n",
    "        while unsplit[txt_ptr:txt_ptr + len(full_word)] != full_word:\n",
    "            txt_ptr += 1\n",
    "        offset_to_wordidx[txt_ptr:txt_ptr + len(full_word)] = split_index\n",
    "        txt_ptr += len(full_word)\n",
    "    return offset_to_wordidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a85544-d1d3-4aa9-821f-d4f3d68e7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_ALL_SUBTOKENS = True\n",
    "\n",
    "class dataset_o(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, get_wids):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.get_wids = get_wids # for validation\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        text = self.data.text[index]        \n",
    "        word_labels = self.data.entities[index] if not self.get_wids else None\n",
    "\n",
    "        # TOKENIZE TEXT\n",
    "        encoding = self.tokenizer(text,\n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        \n",
    "        word_ids = encoding.word_ids()  \n",
    "        split_word_ids = np.full(len(word_ids),-1)\n",
    "        offset_to_wordidx = split_mapping(text)\n",
    "        offsets = encoding['offset_mapping']\n",
    "        \n",
    "        # CREATE TARGETS AND MAPPING OF TOKENS TO SPLIT() WORDS\n",
    "        label_ids = []\n",
    "        # Iterate in reverse to label whitespace tokens until a Begin token is encountered\n",
    "        for token_idx, word_idx in reversed(list(enumerate(word_ids))):\n",
    "            \n",
    "            if word_idx is None:\n",
    "                if not self.get_wids: label_ids.append(-100)\n",
    "            else:\n",
    "                if offsets[token_idx] != (0,0):\n",
    "                    #Choose the split word that shares the most characters with the token if any\n",
    "                    split_idxs = offset_to_wordidx[offsets[token_idx][0]:offsets[token_idx][1]]\n",
    "                    split_index = stats.mode(split_idxs[split_idxs != -1]).mode[0] if len(np.unique(split_idxs)) > 1 else split_idxs[0]\n",
    "                    \n",
    "                    if split_index != -1: \n",
    "                        if not self.get_wids: label_ids.append( labels_to_ids[word_labels[split_index]] )\n",
    "                        split_word_ids[token_idx] = split_index\n",
    "                    else:\n",
    "                        # Even if we don't find a word, continue labeling 'I' tokens until a 'B' token is found\n",
    "                        if label_ids and label_ids[-1] != -100 and ids_to_labels[label_ids[-1]][0] == 'I':\n",
    "                            split_word_ids[token_idx] = split_word_ids[token_idx + 1]\n",
    "                            if not self.get_wids: label_ids.append(label_ids[-1])\n",
    "                        else:\n",
    "                            if not self.get_wids: label_ids.append(-100)\n",
    "                else:\n",
    "                    if not self.get_wids: label_ids.append(-100)\n",
    "        \n",
    "        encoding['labels'] = list(reversed(label_ids))\n",
    "\n",
    "        # CONVERT TO TORCH TENSORS\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        if self.get_wids: \n",
    "            item['wids'] = torch.as_tensor(split_word_ids)\n",
    "        \n",
    "        # https://www.kaggle.com/vuxxxx/tensorflow-longformer-ner-postprocessing#Postprocessing\n",
    "#         item['offsets'] = offsets\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95239219",
   "metadata": {
    "papermill": {
     "duration": 0.166423,
     "end_time": "2021-12-24T18:58:00.631003",
     "exception": false,
     "start_time": "2021-12-24T18:58:00.464580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Train and Validation Dataloaders\n",
    "We will use the same train and validation subsets as my TensorFlow notebook [here][1]. Then we can compare results. And/or experiment with ensembling the validation fold predictions.\n",
    "\n",
    "[1]: https://www.kaggle.com/cdeotte/tensorflow-longformer-ner-cv-0-617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51ea953f",
   "metadata": {
    "papermill": {
     "duration": 0.19708,
     "end_time": "2021-12-24T18:58:00.995662",
     "exception": false,
     "start_time": "2021-12-24T18:58:00.798582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15594 train texts. We will split 90% 10% for validation.\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE VALIDATION INDEXES (that match my TF notebook)\n",
    "IDS = train_df.id.unique()\n",
    "print('There are',len(IDS),'train texts. We will split 90% 10% for validation.')\n",
    "\n",
    "# TRAIN VALID SPLIT 90% 10%\n",
    "np.random.seed(42)\n",
    "train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\n",
    "valid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\n",
    "np.random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e635ad",
   "metadata": {
    "papermill": {
     "duration": 0.420181,
     "end_time": "2021-12-24T18:58:01.582956",
     "exception": false,
     "start_time": "2021-12-24T18:58:01.162775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file model\\added_tokens.json. We won't load it.\n",
      "loading file model\\spiece.model\n",
      "loading file model\\tokenizer.json\n",
      "loading file None\n",
      "loading file model\\special_tokens_map.json\n",
      "loading file model\\tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (15594, 3)\n",
      "TRAIN Dataset: (14034, 2)\n",
      "TEST Dataset: (1560, 3)\n"
     ]
    }
   ],
   "source": [
    "# CREATE TRAIN SUBSET AND VALID SUBSET\n",
    "data = train_text_df[['id','text', 'entities']]\n",
    "train_dataset = data.loc[data['id'].isin(IDS[train_idx]),['text', 'entities']].reset_index(drop=True)\n",
    "test_dataset = data.loc[data['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH) \n",
    "training_set = dataset(train_dataset, tokenizer, config['max_length'], False)\n",
    "testing_set = dataset(test_dataset, tokenizer, config['max_length'], True)\n",
    "# testing_set = dataset_o(test_dataset, tokenizer, config['max_length'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71ffa08c",
   "metadata": {
    "papermill": {
     "duration": 0.213192,
     "end_time": "2021-12-24T18:58:02.079798",
     "exception": false,
     "start_time": "2021-12-24T18:58:01.866606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN DATASET AND VALID DATASET\n",
    "train_params = {'batch_size': config['train_batch_size'],\n",
    "                'shuffle': True,\n",
    "                # 'num_workers': 2,\n",
    "                'num_workers': 0,\n",
    "                'pin_memory':True\n",
    "               }\n",
    "\n",
    "test_params = {'batch_size': config['valid_batch_size'],\n",
    "               'shuffle': False,\n",
    "               # 'num_workers': 2,\n",
    "               'num_workers': 0,\n",
    "               'pin_memory':True\n",
    "              }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "# TEST DATASET\n",
    "test_texts_set = dataset(test_texts, tokenizer, config['max_length'], True)\n",
    "test_texts_loader = DataLoader(test_texts_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9391091-fa86-4442-aa1f-aece06fc549f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  65, 1102, 5247,  ...,    0,    0,    0]),\n",
       " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'labels': tensor([-100,    3,    3,  ..., -100, -100, -100])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe5d0be5-bad2-4c48-8f96-99a41f49c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Segoing Cowboys is a good program that I think everybody should join.[SEP] In the program, you can do things that a cowboy usually does, but you can also do other fun things.[SEP] Here are some other reasons for you to join. If you like animals, this job is for you.[SEP] One of the main reasons this program started was to help countries with animals, and that is a fauna-lover's dream.[SEP] Another reason is that you can see the different sights in other coutries.[SEP] The sights are absolutely amazing! You will be able to see the beautiful sunset on the sea and there is pretty much nothing prettier than that.[SEP] But, if that hasn't changed your minds about not going, then this certainly will. Some people say that seafaring is dangerous, or that you will not make it out alive if the ship sinks.[SEP] First of all, there is absolutely no way that you will get killed on the ship, and second, there is about a fourteen million to one chance that the ship will sink, because our captain is the best in the world.[SEP] Another reason you might not want to go is because you might get seasick.[SEP] I don't think that is a very good reason to ot go, because one, you will get over it and two, the only reason anyone ever threw up on the ship is because he was watching The Exorcist an eating clam chowder.[SEP] But that is a different story for a different time, so we'll be moving on. Please consider joining the Seagoing Cowboys program.[SEP] It helps people out, you can see sights, and it will be the best memory of your entire life.[SEP] You will always be helping somebody, no matter what.[SEP]<pad><pad><pad><pad>\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(training_set[0]['input_ids'][:360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6193f5c-c413-41d9-927a-a290451a62f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(training_set[0]['input_ids'][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "165d0927-ba3d-41d7-a510-2a3e9ea08b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]['labels'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "896b4e97-7367-4512-9008-8be61de445e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100,    3,    3,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
       "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
       "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
       "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
       "           4,    4,    5,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
       "           6,    4,   11,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
       "          12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
       "          12,   12,   12,   12,   12,   12,    0,    0,    0,    0,    5,    6,\n",
       "           6,    6,    6,    6,    6,    6,    6,    6,    6,    6,   11,   12,\n",
       "          12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
       "          12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,   12,\n",
       "          12,   12,   12,   12,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    7,    8,\n",
       "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
       "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    9,   10,\n",
       "          10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
       "          10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
       "          10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
       "          10,   10,   10,   10,   10,   10,   10,   10,   10,    7,    8,    8,\n",
       "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
       "           8,    8,    9,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
       "          10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
       "          10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
       "          10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
       "          10,   10,   10,   10,   10,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   13,\n",
       "          14,   14,   14,   14,   14,   14,   14,   14,    0,   14,   14,   14,\n",
       "          14,   14,   14,   14,   14,   14,   14,   14,   14,   14,   14,   14,\n",
       "          14,   14,   14,   14,   14,   14,   14,   14,   14,   14,   14,   14,\n",
       "          14,   14,   14,   14,   14,   14,   14,   14, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]['labels'][:360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23a40486-35de-4e05-8b8a-69ac83504e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train_dataset['text'][0]\n",
    "pre_text = '[CLS] ' + text.replace('. ', '. [SEP] ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31ae79",
   "metadata": {
    "papermill": {
     "duration": 0.177586,
     "end_time": "2021-12-24T18:58:02.426035",
     "exception": false,
     "start_time": "2021-12-24T18:58:02.248449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Model\n",
    "The PyTorch train function is taken from Raghavendrakotala's great notebook [here][1]. I assume it uses a masked loss which avoids computing loss when target is `-100`. If not, we need to update this.\n",
    "\n",
    "In Kaggle notebooks, we will train our model for 5 epochs `batch_size=4` with Adam optimizer and learning rates `LR = [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7]`. The loaded model was trained offline with `batch_size=8` and `LR = [5e-5, 5e-5, 5e-6, 5e-6, 5e-7]`. (Note the learning rate changes `e-5`, `e-6`, and `e-7`). Using `batch_size=4` will probably achieve a better validation score than `batch_size=8`, but I haven't tried yet.\n",
    "\n",
    "[1]: https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0bb7759",
   "metadata": {
    "papermill": {
     "duration": 0.18811,
     "end_time": "2021-12-24T18:58:02.784655",
     "exception": false,
     "start_time": "2021-12-24T18:58:02.596545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    #tr_preds, tr_labels = [], []\n",
    "    \n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(tqdm(training_loader, total=len(training_loader))):\n",
    "        \n",
    "        ids = batch['input_ids'].to(config['device'], dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(config['device'], dtype = torch.long)\n",
    "        labels = batch['labels'].to(config['device'], dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n",
    "                               return_dict=False)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 1000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss after {idx:04d} training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        #tr_labels.extend(labels)\n",
    "        #tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=config['max_grad_norm']\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a78174ac",
   "metadata": {
    "papermill": {
     "duration": 12.035834,
     "end_time": "2021-12-24T18:58:14.988658",
     "exception": false,
     "start_time": "2021-12-24T18:58:02.952824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"model/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 66,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50358\n",
      "}\n",
      "\n",
      "loading weights file model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BigBirdForTokenClassification.\n",
      "\n",
      "All the weights of BigBirdForTokenClassification were initialized from the model checkpoint at model/pytorch_model.bin.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BigBirdForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# CREATE MODEL\n",
    "config_model = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "                   DOWNLOADED_MODEL_PATH+'/pytorch_model.bin',config=config_model)\n",
    "model.to(config['device'])\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=config['learning_rates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37429c8d-8115-4c48-9988-62c074684912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "def my_forward(\n",
    "    self=model,\n",
    "    input_ids=None,\n",
    "    attention_mask=None,\n",
    "    token_type_ids=None,\n",
    "    position_ids=None,\n",
    "    head_mask=None,\n",
    "    inputs_embeds=None,\n",
    "    labels=None,\n",
    "    output_attentions=None,\n",
    "    output_hidden_states=None,\n",
    "    return_dict=None,\n",
    "):\n",
    "    r\"\"\"\n",
    "    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "    \"\"\"\n",
    "    return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "    outputs = self.bert(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids,\n",
    "        position_ids=position_ids,\n",
    "        head_mask=head_mask,\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        output_attentions=output_attentions,\n",
    "        output_hidden_states=output_hidden_states,\n",
    "        return_dict=return_dict,\n",
    "    )\n",
    "\n",
    "    sequence_output_s = outputs[0] # [bs, 1024, 768]\n",
    "#     print('233')\n",
    "#     print(outputs[0][:,0,:].shape)\n",
    "#     print(outputs[0][:,0,:])\n",
    "#     print(outputs[0].shape)\n",
    "#     print(outputs[0])\n",
    "    # print(input_ids.shape)\n",
    "    \n",
    "    # index = torch.nonzero(input_ids==66)\n",
    "    # sequence_output_s = outputs[0][index[:,0], index[:,1], :]\n",
    "    # print(index.shape)\n",
    "    # print(sequence_output_s.shape)\n",
    "    \n",
    "#     shape = sequence_output[0].shape\n",
    "#     index = torch.nonzero(input_ids[0]==66).flatten()\n",
    "#     sequence_output_s = input_ids[0][index].view(-1, 1,shape[0],shape[1])\n",
    "\n",
    "#     for idx,batch in enumerate(input_ids[1:]):\n",
    "#         index = torch.nonzero(batch==66).flatten()\n",
    "#         torch.cat([sequence_output_s,sequence_output[idx+1][index].view(1, len(index), dim)],dim=0)\n",
    "    \n",
    "    sequence_output_s = self.dropout(sequence_output_s)\n",
    "    logits = self.classifier(sequence_output_s)\n",
    "\n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "    \n",
    "    # print(self.num_labels) # 15\n",
    "    # print(logits.view(-1, self.num_labels).shape) # [bs x 1024, 15]\n",
    "    # print(labels.shape) # [bs, 1024]\n",
    "    # print(loss)\n",
    "\n",
    "    if not return_dict:\n",
    "        output = (logits,) + outputs[2:]\n",
    "        return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "    return TokenClassifierOutput(\n",
    "        loss=loss,\n",
    "        logits=logits,\n",
    "        hidden_states=outputs.hidden_states,\n",
    "        attentions=outputs.attentions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "856da230-7021-4bd0-a733-ac9cde2b19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forward = my_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d321f2ae-c02b-43cd-b7e1-b54e9dae0aee",
   "metadata": {
    "papermill": {
     "duration": 6.881216,
     "end_time": "2021-12-24T18:58:22.040114",
     "exception": false,
     "start_time": "2021-12-24T18:58:15.158898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "## ignore __floordiv__ is deprecated\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# LOOP TO TRAIN MODEL (or load model)\n",
    "if not LOAD_MODEL_FROM:\n",
    "    for epoch in range(config['epochs']):\n",
    "        \n",
    "        print(f\"### Training epoch: {epoch + 1}\")\n",
    "        for g in optimizer.param_groups: \n",
    "            g['lr'] = config['learning_rates'][epoch]\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'### LR = {lr}\\n')\n",
    "        \n",
    "        train(epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    torch.save(model.state_dict(), f'bigbird_v{TRAIN_VER}.pt')\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f'{LOAD_MODEL_FROM}/bigbird_v{LOAD_VER}.pt'))\n",
    "    print('Model loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a16b77d",
   "metadata": {
    "papermill": {
     "duration": 0.172006,
     "end_time": "2021-12-24T18:58:22.383000",
     "exception": false,
     "start_time": "2021-12-24T18:58:22.210994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference and Validation Code\n",
    "We will infer in batches using our data loader which is faster than inferring one text at a time with a for-loop. The metric code is taken from Rob Mulla's great notebook [here][2]. Our model achieves validation F1 score 0.615! \n",
    "\n",
    "During inference our model will make predictions for each subword token. Some single words consist of multiple subword tokens. In the code below, we use a word's first subword token prediction as the label for the entire word. We can try other approaches, like averaging all subword predictions or taking `B` labels before `I` labels etc.\n",
    "\n",
    "[1]: https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "[2]: https://www.kaggle.com/robikscube/student-writing-competition-twitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "239f6c46",
   "metadata": {
    "papermill": {
     "duration": 0.183064,
     "end_time": "2021-12-24T18:58:22.738149",
     "exception": false,
     "start_time": "2021-12-24T18:58:22.555085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(batch):\n",
    "                \n",
    "    # MOVE BATCH TO GPU AND INFER\n",
    "    ids = batch[\"input_ids\"].to(config['device'])\n",
    "    mask = batch[\"attention_mask\"].to(config['device'])\n",
    "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
    "    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy() \n",
    "\n",
    "    # INTERATE THROUGH EACH TEXT AND GET PRED\n",
    "    predictions = []\n",
    "    for k,text_preds in enumerate(all_preds):\n",
    "        token_preds = [ids_to_labels[i] for i in text_preds]\n",
    "\n",
    "        prediction = []\n",
    "        word_ids = batch['wids'][k].numpy()  \n",
    "        previous_word_idx = -1\n",
    "        for idx,word_idx in enumerate(word_ids):                            \n",
    "            if word_idx == -1:\n",
    "                pass\n",
    "            elif word_idx != previous_word_idx:              \n",
    "                prediction.append(token_preds[idx])\n",
    "                previous_word_idx = word_idx\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10e3077d",
   "metadata": {
    "papermill": {
     "duration": 0.18449,
     "end_time": "2021-12-24T18:58:23.115470",
     "exception": false,
     "start_time": "2021-12-24T18:58:22.930980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/zzy990106/pytorch-ner-infer\n",
    "# code has been modified from original\n",
    "def get_predictions(df=test_dataset, loader=testing_loader):\n",
    "    \n",
    "    # put model in training mode\n",
    "    model.eval()\n",
    "    \n",
    "    # GET WORD LABEL PREDICTIONS\n",
    "    y_pred2 = []\n",
    "    for batch in tqdm(loader, total=len(loader)):\n",
    "        labels = inference(batch)\n",
    "        y_pred2.extend(labels)\n",
    "\n",
    "    final_preds2 = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "\n",
    "        idx = df.id.values[i]\n",
    "        #pred = [x.replace('B-','').replace('I-','') for x in y_pred2[i]]\n",
    "        pred = y_pred2[i] # Leave \"B\" and \"I\"\n",
    "        preds = []\n",
    "        j = 0\n",
    "        while j < len(pred):\n",
    "            cls = pred[j]\n",
    "            if cls == 'O': j += 1\n",
    "            else: cls = cls.replace('B','I') # spans start with B\n",
    "            end = j + 1\n",
    "            while end < len(pred) and pred[end] == cls:\n",
    "                end += 1\n",
    "            \n",
    "            if cls != 'O' and cls != '' and end - j > 7:\n",
    "                final_preds2.append((idx, cls.replace('I-',''),\n",
    "                                     ' '.join(map(str, list(range(j, end))))))\n",
    "        \n",
    "            j = end\n",
    "        \n",
    "    oof = pd.DataFrame(final_preds2)\n",
    "    oof.columns = ['id','class','predictionstring']\n",
    "\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b83303a5",
   "metadata": {
    "papermill": {
     "duration": 0.318739,
     "end_time": "2021-12-24T18:58:23.602271",
     "exception": false,
     "start_time": "2021-12-24T18:58:23.283532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from Rob Mulla @robikscube\n",
    "# https://www.kaggle.com/robikscube/student-writing-competition-twitch\n",
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter/ len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id','class','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on=['id','class'],\n",
    "                           right_on=['id','discourse_type'],\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
    "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP') \\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97422c80",
   "metadata": {
    "papermill": {
     "duration": 104.195246,
     "end_time": "2021-12-24T19:00:08.079871",
     "exception": false,
     "start_time": "2021-12-24T18:58:23.884625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [01:15<00:00,  6.90it/s]\n",
      "100%|██████████| 1560/1560 [00:00<00:00, 6830.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:00<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 0.6595460614152203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:00<00:02,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim 0.5308546914530855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:01<00:01,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence 0.7119448037947391\n",
      "Concluding Statement 0.7630252100840336\n",
      "Counterclaim 0.5032139577594124\n",
      "Rebuttal 0.402088772845953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.7831196581196581\n",
      "\n",
      "Overall 0.6219704507817289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_VAL_SCORE: # note this doesn't run during submit\n",
    "    # VALID TARGETS\n",
    "    valid = train_df.loc[train_df['id'].isin(IDS[valid_idx])]\n",
    "\n",
    "    # OOF PREDICTIONS\n",
    "    oof = get_predictions(test_dataset, testing_loader)\n",
    "\n",
    "    # COMPUTE F1 SCORE\n",
    "    f1s = []\n",
    "    CLASSES = oof['class'].unique()\n",
    "    print()\n",
    "    for c in tqdm(CLASSES):\n",
    "        pred_df = oof.loc[oof['class']==c].copy()\n",
    "        gt_df = valid.loc[valid['discourse_type']==c].copy()\n",
    "        f1 = score_feedback_comp(pred_df, gt_df)\n",
    "        print(c, f1)\n",
    "        f1s.append(f1)\n",
    "    print()\n",
    "    print('Overall', np.mean(f1s))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b47e323e-6ab1-4c70-bb2a-8b19a48da526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Position', 'Claim', 'Evidence', 'Concluding Statement',\n",
       "       'Counterclaim', 'Rebuttal', 'Lead'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63626798-d325-4571-8184-0e5b8d5565cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>Position</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>Claim</td>\n",
       "      <td>18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>Claim</td>\n",
       "      <td>145 146 147 148 149 150 151 152 153 154 155 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>161 162 163 164 165 166 167 168 169 170 171 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>262 263 264 265 266 267 268 269 270 271 272 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>336 337 338 339 340 341 342 343 344 345 346 34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                 class  \\\n",
       "0  DD3F7252F887              Position   \n",
       "1  DD3F7252F887                 Claim   \n",
       "2  DD3F7252F887              Evidence   \n",
       "3  DD3F7252F887                 Claim   \n",
       "4  DD3F7252F887              Evidence   \n",
       "5  DD3F7252F887              Evidence   \n",
       "6  DD3F7252F887  Concluding Statement   \n",
       "\n",
       "                                    predictionstring  \n",
       "0        0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \n",
       "1  18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 3...  \n",
       "2  52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 6...  \n",
       "3  145 146 147 148 149 150 151 152 153 154 155 15...  \n",
       "4  161 162 163 164 165 166 167 168 169 170 171 17...  \n",
       "5  262 263 264 265 266 267 268 269 270 271 272 27...  \n",
       "6  336 337 338 339 340 341 342 343 344 345 346 34...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.loc[oof['id']=='DD3F7252F887']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eec7cec0-a045-411a-a431-408bbf2fd310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F6D56988EB7D'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof['id'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cec2452c-ec19-47a1-9a0f-2fc38778ca7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof['predictionstring'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdcff89d-b227-4a8c-a62a-9b1bb5f11147",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = oof.loc[oof['class']==c].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "516978b4-dad7-4ee9-85ef-82952028e1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53662</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619534e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Facial action coding sytsem should be used bec...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53663</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619534e+12</td>\n",
       "      <td>97.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>First off i think if this is being used on stu...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53664</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619534e+12</td>\n",
       "      <td>212.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>and they are to scared to ask for help and in ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53665</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619534e+12</td>\n",
       "      <td>408.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Also if a student is bored this will make the ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53666</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619535e+12</td>\n",
       "      <td>501.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>This is a good way to help people to what if t...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>98 99 100 101 102 103 104 105 106 107 108 109 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53667</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619535e+12</td>\n",
       "      <td>579.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>and they need help or want to talk to somebody...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>114 115 116 117 118 119 120 121 122 123 124 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53668</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619535e+12</td>\n",
       "      <td>741.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>Plus it is cool because you can find out alot...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 4</td>\n",
       "      <td>145 146 147 148 149 150 151 152 153 154 155 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53669</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619535e+12</td>\n",
       "      <td>901.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>This is really cool beacsue you can find out a...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>178 179 180 181 182 183 184 185 186 187 188 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53670</th>\n",
       "      <td>DD3F7252F887</td>\n",
       "      <td>1.619535e+12</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>We have expressions every day but sometimes ca...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>282 283 284 285 286 287 288 289 290 291 292 29...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  discourse_id  discourse_start  discourse_end  \\\n",
       "53662  DD3F7252F887  1.619534e+12              0.0           97.0   \n",
       "53663  DD3F7252F887  1.619534e+12             97.0          211.0   \n",
       "53664  DD3F7252F887  1.619534e+12            212.0          408.0   \n",
       "53665  DD3F7252F887  1.619534e+12            408.0          500.0   \n",
       "53666  DD3F7252F887  1.619535e+12            501.0          579.0   \n",
       "53667  DD3F7252F887  1.619535e+12            579.0          740.0   \n",
       "53668  DD3F7252F887  1.619535e+12            741.0          900.0   \n",
       "53669  DD3F7252F887  1.619535e+12            901.0         1425.0   \n",
       "53670  DD3F7252F887  1.619535e+12           1426.0         1822.0   \n",
       "\n",
       "                                          discourse_text  \\\n",
       "53662  Facial action coding sytsem should be used bec...   \n",
       "53663  First off i think if this is being used on stu...   \n",
       "53664  and they are to scared to ask for help and in ...   \n",
       "53665  Also if a student is bored this will make the ...   \n",
       "53666  This is a good way to help people to what if t...   \n",
       "53667  and they need help or want to talk to somebody...   \n",
       "53668   Plus it is cool because you can find out alot...   \n",
       "53669  This is really cool beacsue you can find out a...   \n",
       "53670  We have expressions every day but sometimes ca...   \n",
       "\n",
       "             discourse_type      discourse_type_num  \\\n",
       "53662              Position              Position 1   \n",
       "53663                 Claim                 Claim 1   \n",
       "53664              Evidence              Evidence 1   \n",
       "53665                 Claim                 Claim 2   \n",
       "53666                 Claim                 Claim 3   \n",
       "53667              Evidence              Evidence 2   \n",
       "53668                 Claim                 Claim 4   \n",
       "53669              Evidence              Evidence 3   \n",
       "53670  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                        predictionstring  \n",
       "53662        0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \n",
       "53663  18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 3...  \n",
       "53664  41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 5...  \n",
       "53665  78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 9...  \n",
       "53666  98 99 100 101 102 103 104 105 106 107 108 109 ...  \n",
       "53667  114 115 116 117 118 119 120 121 122 123 124 12...  \n",
       "53668  145 146 147 148 149 150 151 152 153 154 155 15...  \n",
       "53669  178 179 180 181 182 183 184 185 186 187 188 18...  \n",
       "53670  282 283 284 285 286 287 288 289 290 291 292 29...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.loc[valid['id']=='DD3F7252F887']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "955b05a3-2a7f-4e82-a84f-52a6cfbe8f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = valid.loc[valid['id']=='DD3F7252F887']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c74f20f8-7b9d-4f99-9c32-cfd5ecbfa333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['predictionstring'][53670]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "530c30c3-9204-487b-b450-fe5351d1a590",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mL:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mL:\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mL:\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 9",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12048/3960010056.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mL:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mL:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mL:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 9"
     ]
    }
   ],
   "source": [
    "pred_df['id'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c952e",
   "metadata": {
    "papermill": {
     "duration": 0.167874,
     "end_time": "2021-12-24T19:00:08.424099",
     "exception": false,
     "start_time": "2021-12-24T19:00:08.256225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer Test Data and Write Submission CSV\n",
    "We will now infer the test data and write submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1ed92",
   "metadata": {
    "papermill": {
     "duration": 0.759469,
     "end_time": "2021-12-24T19:00:09.351580",
     "exception": false,
     "start_time": "2021-12-24T19:00:08.592111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = get_predictions(test_texts, test_texts_loader)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dec595",
   "metadata": {
    "papermill": {
     "duration": 0.180565,
     "end_time": "2021-12-24T19:00:09.707700",
     "exception": false,
     "start_time": "2021-12-24T19:00:09.527135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed65a6-823f-443d-81f6-1d9adbc31bca",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b886353c-2081-43ab-8086-28540b00d0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.16.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8d58d89-09d2-4280-87ef-3b9b5c9a68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.0\n"
     ]
    }
   ],
   "source": [
    "import tokenizers\n",
    "print(tokenizers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39de66f7-fc6e-47dc-872a-8ae90cdd3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "print(torch. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8bd4d64-5461-4ae6-8bee-aa938a12d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[1,2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0abe6f86-fce8-425c-98d8-8ad5d2af2a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58225049-39de-4b16-b811-817e88540dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fae476df-031c-47d0-a28d-0674c7ba21be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0], dtype=int64),\n",
       " array([0, 0], dtype=int64),\n",
       " array([0, 1], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3880c7a-a438-4a46-a26b-b6984bb5ca49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 228.514779,
   "end_time": "2021-12-24T19:00:12.608880",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-24T18:56:24.094101",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
